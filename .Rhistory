combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
# Convert to a factor
combi$Title <- factor(combi$Title)
# Engineered variable: Family size
combi$FamilySize <- combi$SibSp + combi$Parch + 1
# Engineered variable: Family
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
# Delete erroneous family IDs
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
# Convert to a factor
combi$FamilyID <- factor(combi$FamilyID)
# Fill in all the missing Ages NA's
summary(combi$Age)
###########################################################################################
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
##   0.17   21.00   28.00   29.88   39.00   80.00     263
###########################################################################################
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize,
data=combi[!is.na(combi$Age),], method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
summary(combi) ## check if something is still missing e.g Fare
#Embarked, All missing Embarked -> just make them embark from most common place
summary(combi$Embarked) ## check for Embarked missing data
which(combi$Embarked == '')## get id for missing data ## 62 830
combi$Embarked[c(62,830)] = "S" ## fill it with S
combi$Embarked <- factor(combi$Embarked)
# All the missing Fares -> assume median of their respective class
summary(combi$Fare) ## check if fare is missing NA's ->1
which(is.na(combi$Fare)) ## get id for missing data
combi$Fare[1044] <- median(combi$Fare, na.rm=TRUE) ## add median fare to missing data
# New factor for Random Forests, only allowed <32 levels, so reduce number
combi$FamilyID2 <- combi$FamilyID
# Convert back to string
combi$FamilyID2 <- as.character(combi$FamilyID2)
combi$FamilyID2[combi$FamilySize <= 3] <- 'Small'
# And convert back to factor
combi$FamilyID2 <- factor(combi$FamilyID2)
# Split back into test and train data sets also it is necessary to remove all the missing data from
## the data pool in order to apply Random Forest.
train <- combi[1:500,]
#test <- combi[892:1309,]
test <- combi[501:891,]
test
head(test)
test_test = test
test_train = train
mdl_svm <- svm(Survived ~ Pclass + Sex + SibSp+Parch+Fare, data = test_train, kernel = "sigmoid")
mdl_svm
#
# prepare test data
#
str(test_test)
#test_test$Survived <- NULL
#
pred <- predict(mdl_svm,newdata = (test_test %>% select(-PassengerId)))
pred
out <- data.frame(PassengerId = test_test$PassengerId, Survived = pred)
head(out)
library(e1071)
mdl_svm <- svm(Survived ~ Pclass + Sex + SibSp+Parch+Fare, data = train, kernel = "sigmoid")
mdl_svm
#
# prepare test data
#
str(test)
#test$Survived <- NULL
#
pred <- predict(mdl_svm,newdata = (test %>% select(-PassengerId)))
pred
out <- data.frame(PassengerId = test$PassengerId, Survived = pred)
head(out)
#
out <- test %>% select(PassengerId,Survived)
#########################################################################
### Mean square prediction error
out$Survived <- ifelse(out$Survived == 2,1,0)
actual.out <- data.frame(PassengerID = test$PassengerId, Survived = test$Survived)
MSPE = mean((out$Survived-actual.out$Survived)^2)
cat(" Mean Square prediction error is : -> ", MSPE)
head(out)
head(test)
mdl_svm <- svm(Survived ~ Pclass + Sex + SibSp+Parch+Fare, data = train, kernel = "sigmoid") ## sigmoid kernel
mdl_svm
str(test)
pred <- predict(mdl_svm,newdata = test)
pred
out <- data.frame(PassengerId = test$PassengerId, Survived = pred)
head(out)
str(test)
pred <- predict(mdl_svm,newdata = test)
pred
out <- data.frame(PassengerId = test$PassengerId, Survived = pred)
head(out)
#
#out <- test %>% select(PassengerId,Survived)
#########################################################################
### Mean square prediction error
out$Survived <- ifelse(out$Survived == 2,1,0)
actual.out <- data.frame(PassengerID = test$PassengerId, Survived = test$Survived)
MSPE = mean((out$Survived-actual.out$Survived)^2)
cat(" Mean Square prediction error is : -> ", MSPE)
head(test)
head(train)
mdl_svm <- svm(Survived ~ Pclass + Sex +Fare, data = train, kernel = "sigmoid") ## sigmoid kernel
mdl_svm
str(test)
pred <- predict(mdl_svm,newdata = test)
pred
out <- data.frame(PassengerId = test$PassengerId, Survived = pred)
head(out)
out$Survived <- ifelse(out$Survived == 2,1,0)
actual.out <- data.frame(PassengerID = test$PassengerId, Survived = test$Survived)
MSPE = mean((out$Survived-actual.out$Survived)^2)
cat(" Mean Square prediction error is : -> ", MSPE)
head(out)
actual.out <- data.frame(PassengerID = test$PassengerId, Survived = test$Survived)
MSPE = mean((out$Survived-actual.out$Survived)^2)
cat(" Mean Square prediction error is : -> ", MSPE)
as.factor(test)
as.factor(test$Embarked)
train <- combi[1:500,]
#test <- combi[892:1309,]
test <- combi[501:891,]
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID2,
data=train, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
fit$confusion
head(test)
accuracy = sum(Prediction==test$Survived)/length(Prediction)
print (sprintf("Accuracy = %3.2f %%",accuracy*100))
library(Amelia)
install.packages(Amelia)
install.packages("Amelia"")
""
install.packages("Amelia")
library(Amelia)
missmap(test, main = "Missingness Map Test")
missmap(df_test, main = "Missingness Map Test")
missmap(df_train, main = "Missingness Map Test")
library(Amelia)
missmap(df_train, main = "Missing Map train")
missmap(df_test, main = "Missing Map Test")
forest.model1 <- train(survived ~ pclass + sex + title + sibsp +parch ,
train,
importance=TRUE)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
gbm.model <- train(survived ~ pclass + sex + title + sibsp +parch ,
train,
distribution = "gaussian",
method = "gbm",
trControl = fitControl,
verbose = FALSE)
install.packages("caret")
install.packages("caret")
library(caret)
forest.model1 <- train(survived ~ pclass + sex + title + sibsp +parch ,
train,
importance=TRUE)
("caret")
forest.model <- train(Survived ~ Pclass + Sex + Title + Sibsp +Parch ,
train,
importance=TRUE)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
gbm.model <- train(survived ~ pclass + sex + title + sibsp +parch ,
train,
distribution = "gaussian",
method = "gbm",
trControl = fitControl,
verbose = FALSE)
library(caret)
forest.model <- train(Survived ~ Pclass + Sex + Title + Sibsp +Parch ,
train,
importance=TRUE)
train
head(train)
forest.model <- train(Survived ~ Pclass + Sex + Title + SibSp +Parch ,
train,
importance=TRUE)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
gbm.model <- train(Survived ~ Pclass + Sex + Title + Sibsp +P`arch ,
train,
distribution = "gaussian",
method = "gbm",
trControl = fitControl,
verbose = FALSE)
)
""
""
))
library(caret)
forest.model <- train(Survived ~ Pclass + Sex + Title + SibSp +Parch ,
train,
importance=TRUE)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
gbm.model <- train(Survived ~ Pclass + Sex + Title + SibSp +P`arch ,
train,
distribution = "gaussian",
method = "gbm",
trControl = fitControl,
verbose = FALSE)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
gbm.model <- train(Survived ~ Pclass + Sex + Title + SibSp +Parch ,
train,
distribution = "gaussian",
method = "gbm",
trControl = fitControl,
verbose = FALSE)
gbm.model <- train(Survived ~ Pclass + Sex + Title + SibSp +Parch ,
train,
distribution = "gaussian",
method = "gbm",
trControl = fitControl,
verbose = FALSE)
gbm.model <- train(Survived ~ Pclass + Sex + Title + SibSp +Parch , train, distribution = "gaussian", method = "gbm",
importance=TRUE, trControl = fitControl,verbose = FALSE)
gmb.model
gbm.model
gbm.model <- train(Survived ~ Pclass + Sex + Title + SibSp +Parch , train, distribution = "gaussian", method = "gbm",
importance=TRUE, trControl = fitControl,verbose = FALSE)
# Look at variable importance
importance(gbm.model)
varImpPlot(gbm.model)
install.packages("pROC")
predict<- predict(forest.model , test , type="prob")
predict<- predict(forest.model , test , type="prob")
function (object, newdata, type = "response", norm.votes = TRUE,
library(caret)
library(pROC)
predict(forest.model , test , type="prob")
predict(forest.model , test , type="prob")
predict<- predict(forest.model , test , type="prob")
predict(forest.model, data.test, type="prob")
predict(forest.model, data.test, type="prob")
predict(forest.model, df_test, type="prob")
head(df_test)
forest.model <- train(Survived ~ Pclass + Sex + SibSp +Parch , train, importance=TRUE)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
gbm.model <- train(Survived ~ Pclass + Sex + SibSp +Parch , train, distribution = "gaussian", method = "gbm",
importance=TRUE, trControl = fitControl,verbose = FALSE)
# Look at variable importance
importance(gbm.model)
varImpPlot(gbm.model)
head(df_test)
predict(forest.model, df_test, type="prob")
predict(forest.model, df_test, )
predict(forest.model, data.test, type="prob")
predict<- predict(forest.model , test )
result.roc.model1 <-  roc(test$Survived, predict$yes)
predict
head(predict)
result.roc.model1 <-  roc(test$Survived, predict)
plot(result.roc.model1, print.thres="best", print.thres.best.method="closest.topleft")
result.coords.model1 <- coords(  result.roc.model1, "best", best.method="closest.topleft",
ret=c("threshold", "accuracy"))
result.coords.model1
library(caret)
library(pROC)
forest.model <- train(Survived ~ Pclass + Sex + SibSp +Parch , train, importance=TRUE)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
gbm.model <- train(Survived ~ Pclass + Sex + SibSp +Parch , train, distribution = "gaussian", method = "gbm",
importance=TRUE, trControl = fitControl,verbose = FALSE)
# Look at variable importance
#
# prediction
#predict<- predict(forest.model , test , type="prob")
predict<- predict(forest.model , test )
result.roc.model1 <-  roc(test$Survived, predict)
plot(result.roc.model1, print.thres="best", print.thres.best.method="closest.topleft")
result.coords.model1 <- coords(  result.roc.model1, "best", best.method="closest.topleft",
ret=c("threshold", "accuracy"))
result.coords.model1
print
predict
forest.model <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID, , train, importance=TRUE)
## 10-fold CV
forest.model <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID, , train, importance=TRUE)
## 10-fold CV
forest.model <- train(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID, , train, importance=TRUE)
## 10-fold CV
head(train)
forest.model <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID, train, importance=TRUE)
## 10-fold CV
edict(forest.model , test , type="prob")
predict<- predict(forest.model , test )
### Plot ROC curve.
result.roc.model1 <-  roc(test$Survived, predict)
plot(result.roc.model1, print.thres="best", print.thres.best.method="closest.topleft")
result.coords.model1 <- coords(  result.roc.model1, "best", best.method="closest.topleft",
ret=c("threshold", "accuracy"))
result.coords.model1
predict
out <- data.frame(PassengerId = test$PassengerId, Survived = predict)
head(out)
actual.out <- data.frame(PassengerID = test$PassengerId, Survived = test$Survived)
MSPE = mean((out$Survived-actual.out$Survived)^2)
cat(" Mean Square prediction error is : -> ", MSPE)
out
out$Survived
head(out)
out$Survived <- ifelse(out$Survived == 2,1,0)
actual.out <- data.frame(PassengerID = test$PassengerId, Survived = test$Survived)
MSPE = mean((out$Survived-actual.out$Survived)^2)
cat(" Mean Square prediction error is : -> ", MSPE)
#Join together the test and train datasets
df_test$Survived <- NA
combi <- rbind(df_train, df_test)
# Convert to a string
combi$Name <- as.character(combi$Name)
# Engineered variable: Title
combi$Title <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]})
combi$Title <- sub(' ', '', combi$Title)
# Combine small title groups
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
# Convert to a factor
combi$Title <- factor(combi$Title)
# Engineered variable: Family size
combi$FamilySize <- combi$SibSp + combi$Parch + 1
# Engineered variable: Family
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
# Delete erroneous family IDs
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
# Convert to a factor
combi$FamilyID <- factor(combi$FamilyID)
# Fill in all the missing Ages NA's
summary(combi$Age)
###########################################################################################
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
##   0.17   21.00   28.00   29.88   39.00   80.00     263
###########################################################################################
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize,
data=combi[!is.na(combi$Age),], method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
summary(combi) ## check if something is still missing e.g Fare
#Embarked, All missing Embarked -> just make them embark from most common place
summary(combi$Embarked) ## check for Embarked missing data
which(combi$Embarked == '')## get id for missing data ## 62 830
combi$Embarked[c(62,830)] = "S" ## fill it with S
combi$Embarked <- factor(combi$Embarked)
# All the missing Fares -> assume median of their respective class
summary(combi$Fare) ## check if fare is missing NA's ->1
which(is.na(combi$Fare)) ## get id for missing data
combi$Fare[1044] <- median(combi$Fare, na.rm=TRUE) ## add median fare to missing data
# New factor for Random Forests, only allowed <32 levels, so reduce number
combi$FamilyID2 <- combi$FamilyID
# Convert back to string
combi$FamilyID2 <- as.character(combi$FamilyID2)
combi$FamilyID2[combi$FamilySize <= 3] <- 'Small'
# And convert back to factor
combi$FamilyID2 <- factor(combi$FamilyID2)
# Split back into test and train data sets also it is necessary to remove all the missing data from
## the data pool in order to apply Random Forest.
train <- combi[1:500,]
#test <- combi[892:1309,]
test <- combi[501:891,]
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID2,
data=train, importance=TRUE, ntree=1000)
# Look at variable importance
importance(fit)
varImpPlot(fit)
#
fit$confusion
##########################################################################
##        0   1 class.error
##    0 277  30  0.09771987
##    1  51 142  0.26424870
##########################################################################
# Now let's make a prediction of survival rate and display in csv file.
Prediction <- predict(fit, test)
out <- data.frame(PassengerID = test$PassengerId, Survived = as.numeric(Prediction))
#########################################################################
## calculate accuracy of model
accuracy = sum(Prediction==test$Survived)/length(Prediction)
print (sprintf("Accuracy = %3.2f %%",accuracy*100)) ### 81.84% accuracy of model using random forest
#########################################################################
train <- combi[1:500,]
#test <- combi[892:1309,]
test <- combi[501:891,]
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked  + FamilySize + FamilyID2,
data=train, importance=TRUE, ntree=1000)
# Look at variable importance
importance(fit)
varImpPlot(fit)
#
fit$confusion
##########################################################################
##        0   1 class.error
##    0 277  30  0.09771987
##    1  51 142  0.26424870
##########################################################################
# Now let's make a prediction of survival rate and display in csv file.
Prediction <- predict(fit, test)
out <- data.frame(PassengerID = test$PassengerId, Survived = as.numeric(Prediction))
#########################################################################
## calculate accuracy of model
accuracy = sum(Prediction==test$Survived)/length(Prediction)
print (sprintf("Accuracy = %3.2f %%",accuracy*100)) ### 81.84% accuracy of model using random forest
#########################################################################
# Split back into test and train data sets also it is necessary to remove all the missing data from
## the data pool in order to apply Random Forest.
train <- combi[1:500,]
#test <- combi[892:1309,]
test <- combi[501:891,]
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked  + FamilySize + FamilyID2,
data=train, importance=TRUE, ntree=1000)
# Look at variable importance
importance(fit)
plot(varImpPlot(fit), top =20)
plot(varImpPlot(fit))
varImpPlot(fit)
importance(fit)
plot(varImpPlot(fit), type='o')
plot(varImpPlot(fit), type ='o')
#
install.packages("party")
install.packages("party")
library(party)
library(party)
fit <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data = train, controls=cforest_unbiased(ntree=2000, mtry=3))
#prediction
Prediction <- predict(fit, test, OOB=TRUE, type = "response")
out <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
accuracy = sum(Prediction==out$Survived)/length(Prediction)
print (sprintf("Accuracy = %3.2f %%",accuracy*100)) ### 81.84% accuracy of model using random forest
write.csv(out, file = "data-cleanup/ciRandomForest-predict.csv", row.names = FALSE)
train <- combi[1:891,]
test <- combi[892:1309,]
library(party)
fit <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data = train, controls=cforest_unbiased(ntree=2000, mtry=3))
#prediction
Prediction <- predict(fit, test, OOB=TRUE, type = "response")
out <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
head(out)
write.csv(out, file = "data-cleanup/ciRandomForest-predict.csv", row.names = FALSE)
ctree(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data = train)
cforest.ctree = ctree(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data = train)
cforest.ctree
plot(train$Survived ~ as.factor(where(cforest.ctree)))
lda
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
fit <- lda(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data = train)
##########################################################################
library(MASS)
fit <- lda(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data = train)
lda
train <- combi[1:500,]
#test <- combi[892:1309,]
test <- combi[501:891,]
head(test)
library(party)
fit <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data = train, controls=cforest_unbiased(ntree=2000, mtry=3))
cforest.ctree = ctree(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data = train)
plot(train$Survived ~ as.factor(where(cforest.ctree)))
#prediction
Prediction <- predict(fit, test, OOB=TRUE, type = "response")
## calculate accuracy of model
accuracy = sum(Prediction==test$Survived)/length(Prediction)
print (sprintf("Accuracy = %3.2f %%",accuracy*100)) ### 100% accuracy of model using random forest
library(MASS)
library("MASS")
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
